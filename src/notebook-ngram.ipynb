{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4ba110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/haw/4semester/nlp/lab03/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from collections import defaultdict\n",
    "\n",
    "# Dataloading step\n",
    "#! Trust remote code sounds a bit unwise but i guess i have to trust\n",
    "pre_procress_dataset = datasets.load_dataset('ptb_text_only', split='train', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa0e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing step:\n",
    "\n",
    "def add_stop_token_batch(batch, sentence_column, stop_token=\"<stop>\"):\n",
    "    \"\"\"Adds stop token to input dataset\"\"\"\n",
    "    new_texts = [sentence + ' ' + stop_token for sentence in batch[sentence_column]]\n",
    "\n",
    "    return {sentence_column: new_texts}\n",
    "\n",
    "def filter_short_sentence_batch(batch, sentence_column, min_words: int=3):\n",
    "    \"\"\"Filters out any sentence with less than min_words\"\"\"\n",
    "    new_text = [len(sentence.split()) >= min_words for sentence in batch[sentence_column]]\n",
    "    return new_text\n",
    "\n",
    "\n",
    "dataset_stop_token = pre_procress_dataset.map(\n",
    "    add_stop_token_batch,\n",
    "    batched=True,\n",
    "    fn_kwargs={'sentence_column': 'sentence'} \n",
    ")\n",
    "\n",
    "dataset = dataset_stop_token.filter(\n",
    "    filter_short_sentence_batch,\n",
    "    batched=True,\n",
    "    fn_kwargs={'sentence_column': 'sentence'}\n",
    ")\n",
    "\n",
    "dataset_split = dataset.train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c2f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rares(threshold):\n",
    "    \"\"\"\n",
    "    This is much better than the suggested way in the assignment,\n",
    "    The assignment didnt make sense at all, why the fuck should i \n",
    "    implement a remove_rares functuin that takes in two datasets?\n",
    "    \"\"\"\n",
    "    counter_dict = defaultdict(int)\n",
    "    for sentence in dataset_split['train']['sentence']:\n",
    "        for word in sentence.split():\n",
    "                counter_dict[word] += 1\n",
    "\n",
    "    return {word for word, count in counter_dict.items() if count < threshold}\n",
    "\n",
    "\n",
    "def replace_rares_batch(batch, rares):\n",
    "    \"\"\"Replaces words present in rares with '<unk>'.\"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in batch['sentence']:\n",
    "        new_sentence_parts = []\n",
    "        for word in sentence.split():\n",
    "            if word in rares:\n",
    "                new_sentence_parts.append('<unk>')\n",
    "            else:\n",
    "                new_sentence_parts.append(word)\n",
    "        new_sentences.append(' '.join(new_sentence_parts))\n",
    "    return {'sentence': new_sentences}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc694ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence'],\n",
      "        num_rows: 33544\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence'],\n",
      "        num_rows: 8387\n",
      "    })\n",
      "})\n",
      "it was worth it just for the look on albert 's face <stop>\n",
      "translation motorola appears to have taken a hitachi technology that is <unk> in the u.s. hitachi says and tried to make it look like a new technology <stop>\n",
      "<unk> <unk> N years old has lived in the district most of her life <stop>\n",
      "so far though there have been no allegations that the contributions the ldp members received amounted to <unk> <stop>\n",
      "volume N shares <stop>\n"
     ]
    }
   ],
   "source": [
    "print(dataset_split)\n",
    "for i in range(5):\n",
    "    print(dataset_split['train'][i]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9870c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_unigram(train_set):\n",
    "    \"\"\"\n",
    "    Basic unigram model that simply counts all words\n",
    "    and returns them as keys with there probalbility as values\n",
    "    \"\"\"\n",
    "    total_words = 0\n",
    "    model_dict = defaultdict(int) #! i didnt know that int() returns 0 this could be good to keep in minde BUT HERE WE NEED INT WIHTOUT () THIS IS VERY CONFUSING!!!\n",
    "    model = {}\n",
    "    for sentence in train_set:\n",
    "        for word in sentence.split():\n",
    "            model_dict[word] += 1\n",
    "            total_words += 1\n",
    "    \n",
    "    for key in model_dict.keys():\n",
    "        model[key] = (model_dict[key] / total_words)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9244ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def unigram_sentence_logp(sentence, model):\n",
    "    \"\"\" \n",
    "    This is the corss-entropy formula from the lecture/assignment,\n",
    "    we look at each word of a sentence and calculate the log\n",
    "    and add them up to get the probability of the sentence.\n",
    "    If we dont know a word -> Prob = 0. the log would be -inf!\n",
    "    BUT per formula we take the negativ log so it would become inf!\n",
    "    BUT this does not feel good to me, i would rather still return the negativ inf.\n",
    "    Not Shure if returning this is what we should do here, but thats the way i like it.\n",
    "    \"\"\"\n",
    "    total_log = 0.0 #! Dont forget that we need float here!\n",
    "\n",
    "    for word in sentence.split():\n",
    "        if word in model:\n",
    "            total_log += -(math.log2(model[word])) #! I use -log2 here because we use -log2 in the cross-entropy formula\n",
    "        else:\n",
    "            return float('-inf')\n",
    "    \n",
    "    return total_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d879818",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = estimate_unigram(dataset_split['train']['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b246fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.067479363498016\n",
      "55.44314259138373\n"
     ]
    }
   ],
   "source": [
    "print(unigram_sentence_logp(\"the the the <stop>\", model))\n",
    "print(unigram_sentence_logp(\"i love computer science <stop>\", model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c19056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_perplexity(dataset, model):\n",
    "    \"\"\"\n",
    "    This is the Perplexity formula from the lecture/assignment.\n",
    "    We now add up the log2 of each sentence in the dataset(test set)\n",
    "    and then we just divide the log with the number of words (cross-entropy).\n",
    "    Then we calculate and return the perpelecity by raising 2 to the power of the cross-entropy\n",
    "    \"\"\"\n",
    "    dataset_log = 0.0\n",
    "    dataset_words = 0\n",
    "\n",
    "    for sentence in dataset['sentence']:\n",
    "        sentence_log = unigram_sentence_logp(sentence, model)\n",
    "        if sentence_log == float('-inf'):\n",
    "            continue\n",
    "        dataset_log += sentence_log\n",
    "        dataset_words += len(sentence)\n",
    "    \n",
    "    if dataset_words == 0:\n",
    "        raise Exception(\"There are no valid sentences!\")\n",
    "    \n",
    "    print('Dataset Log:',dataset_log)\n",
    "    print('Words:',dataset_words)\n",
    "    h = dataset_log / dataset_words\n",
    "    perplexity = 2**h\n",
    "\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c01f42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Log: 1763984.8268081625\n",
      "Words: 1060126\n",
      "3.1688049063181993\n"
     ]
    }
   ],
   "source": [
    "print(unigram_perplexity(dataset_split['test'], model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d74f3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 33544/33544 [00:00<00:00, 402574.45 examples/s]\n",
      "Map: 100%|██████████| 8387/8387 [00:00<00:00, 376207.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "rares = get_rares(5)\n",
    "\n",
    "dataset_split['train'] = dataset_split['train'].map(\n",
    "    replace_rares_batch,\n",
    "    batched=True,\n",
    "    fn_kwargs={'rares_set': rares}\n",
    ")\n",
    "\n",
    "dataset_split['test'] = dataset_split['test'].map(\n",
    "    replace_rares_batch,\n",
    "    batched=True,\n",
    "    fn_kwargs={'rares_set': rares} \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "709aaeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = estimate_unigram(dataset_split['train']['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b03f6a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Log: 1737400.6763911191\n",
      "Words: 1055104\n",
      "3.1310856219188477\n"
     ]
    }
   ],
   "source": [
    "print(unigram_perplexity(dataset_split['test'], model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
